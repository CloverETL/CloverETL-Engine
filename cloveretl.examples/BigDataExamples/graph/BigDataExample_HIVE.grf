<?xml version="1.0" encoding="UTF-8"?>
<Graph author="Wesley" created="Tue Dec 04 11:38:53 CET 2012" guiVersion="0.0.0.devel" id="1354619086069" licenseCode="Javlin-Internal-License" licenseType="Commercial" modified="Mon Jan 13 18:37:44 CET 2014" modifiedBy="User" name="BigDataGraph" revision="1.79" showComponentDetails="true">
<Global>
<Metadata id="Metadata1" previewAttachmentCharset="ISO-8859-1">
<Record fieldDelimiter="|" name="recordName" previewAttachmentCharset="ISO-8859-1" recordDelimiter="\n" recordSize="-1" type="delimited">
<Field eofAsDelimiter="false" label="NAMELAST" name="NAMELAST" nullable="true" shift="0" size="0" type="string"/>
<Field eofAsDelimiter="false" label="NAMEFIRST" name="NAMEFIRST" nullable="true" shift="0" size="0" type="string"/>
<Field eofAsDelimiter="false" label="NAMEMID" name="NAMEMID" nullable="true" shift="0" size="0" type="string"/>
<Field eofAsDelimiter="false" label="APPT_START_DATE" name="APPT_START_DATE" nullable="true" shift="0" size="0" type="string"/>
<Field eofAsDelimiter="false" label="MEETING_LOC" name="MEETING_LOC" nullable="true" shift="0" size="0" type="string"/>
<Field eofAsDelimiter="false" label="MEETING_ROOM" name="MEETING_ROOM" nullable="true" shift="0" size="0" type="string"/>
</Record>
</Metadata>
<Metadata id="Metadata0" previewAttachment="${DATAIN_DIR}/White_House_Visitor_Records_Requests.csv" previewAttachmentCharset="ISO-8859-1">
<Record fieldDelimiter="," label="White_House_Visitor_Records_Requests.csv" name="White_House_Visitor_Records_Requests_csv" previewAttachment="${DATAIN_DIR}/White_House_Visitor_Records_Requests.csv" previewAttachmentCharset="ISO-8859-1" quoteChar="both" quotedStrings="false" recordDelimiter="\n" skipSourceRows="1" type="delimited">
<Field label="NAMELAST" name="NAMELAST" type="string"/>
<Field label="NAMEFIRST" name="NAMEFIRST" type="string"/>
<Field label="NAMEMID" name="NAMEMID" type="string"/>
<Field label="UIN" name="UIN" type="string"/>
<Field label="BDGNBR" name="BDGNBR" type="string"/>
<Field label="Type of Access" name="Type_of_Access" type="string"/>
<Field label="TOA" name="TOA" type="string"/>
<Field label="POA" name="POA" type="string"/>
<Field label="TOD" name="TOD" type="string"/>
<Field label="POD" name="POD" type="string"/>
<Field label="APPT_MADE_DATE" name="APPT_MADE_DATE" type="string"/>
<Field label="APPT_START_DATE" name="APPT_START_DATE" type="string"/>
<Field label="APPT_END_DATE" name="APPT_END_DATE" type="string"/>
<Field label="APPT_CANCEL_DATE" name="APPT_CANCEL_DATE" type="string"/>
<Field label="Total_People" name="Total_People" type="string"/>
<Field label="LAST_UPDATEDBY" name="LAST_UPDATEDBY" type="string"/>
<Field label="POST" name="POST" type="string"/>
<Field label="LastEntryDate" name="LastEntryDate" type="string"/>
<Field label="TERMINAL_SUFFIX" name="TERMINAL_SUFFIX" type="string"/>
<Field label="visitee_namelast" name="visitee_namelast" type="string"/>
<Field label="visitee_namefirst" name="visitee_namefirst" type="string"/>
<Field label="MEETING_LOC" name="MEETING_LOC" type="string"/>
<Field label="MEETING_ROOM" name="MEETING_ROOM" type="string"/>
<Field label="CALLER_NAME_LAST" name="CALLER_NAME_LAST" type="string"/>
<Field label="CALLER_NAME_FIRST" name="CALLER_NAME_FIRST" type="string"/>
<Field label="CALLER_ROOM" name="CALLER_ROOM" type="string"/>
<Field label="Description" name="Description" type="string"/>
<Field eofAsDelimiter="false" label="RELEASE_DATE" name="RELEASE_DATE" type="string"/>
</Record>
</Metadata>
<Connection dbDriver="org.apache.hive.jdbc.HiveDriver" dbURL="jdbc:hive2://hive.yourhost.com:10000/default" driverLibrary="${LIB_DIR}/hadoop/cdh560/hive/hive-exec-1.1.0-cdh5.6.0.jar;${LIB_DIR}/hadoop/cdh560/hive/hive-jdbc-1.1.0-cdh5.6.0.jar;${LIB_DIR}/hadoop/cdh560/hive/hive-metastore-1.1.0-cdh5.6.0.jar;${LIB_DIR}/hadoop/cdh560/hive/hive-service-1.1.0-cdh5.6.0.jar;${LIB_DIR}/hadoop/cdh560/hive/libfb303-0.9.2.jar;${LIB_DIR}/hadoop/cdh560/hive/slf4j-api-1.7.5.jar;${LIB_DIR}/hadoop/cdh560/hive/slf4j-log4j12-1.7.5.jar;${LIB_DIR}/hadoop/cdh560/hadoop-common-2.6.0-cdh5.6.0.jar" id="LOCAL_HIVE" jdbcSpecific="HIVE" name="Local Hive" type="JDBC"/>
<Connection hadoopJar="${LIB_DIR}/hadoop/cdh560/avro-1.7.6-cdh5.6.0.jar;${LIB_DIR}/hadoop/cdh560/guava-15.0.jar;${LIB_DIR}/hadoop/cdh560/hadoop-auth-2.6.0-cdh5.6.0.jar;${LIB_DIR}/hadoop/cdh560/hadoop-common-2.6.0-cdh5.6.0.jar;${LIB_DIR}/hadoop/cdh560/hadoop-hdfs-2.6.0-cdh5.6.0.jar;${LIB_DIR}/hadoop/cdh560/htrace-core4-4.0.1-incubating.jar;${LIB_DIR}/hadoop/cdh560/protobuf-java-2.5.0.jar;${LIB_DIR}/hadoop/cdh560/servlet-api-3.0.jar" host="namenode.yourhost.com" id="LOCAL_HADOOP" name="Local Hadoop" type="HADOOP"/>
<GraphParameters>
<GraphParameterFile fileURL="workspace.prm"/>
</GraphParameters>
<RichTextNote backgroundColor="404040" enabled="true" folded="false" fontSize="medium" height="84" id="Note3" textColor="FFFFFF" width="922" x="20" y="20">
<attr name="text"><![CDATA[h3. Big Data Example: HDFS Storage and HIVE Table

Store a CSV file into HDFS and then convert it into a HIVE table using CloverETL]]></attr>
</RichTextNote>
<RichTextNote backgroundColor="FFFFFF" enabled="true" folded="false" fontSize="medium" height="384" id="Note2" textColor="000000" width="167" x="20" y="103">
<attr name="text"><![CDATA[h3. A. Scenario
To use HDFS for large file storage.

For data files stored in HDFS, there is also an option to convert it into a structured database format in HIVE, given that the file is in a convertable data format]]></attr>
</RichTextNote>
<RichTextNote backgroundColor="FFFFFF" enabled="true" folded="false" fontSize="medium" height="384" id="Note5" textColor="000000" width="255" x="186" y="103">
<attr name="text"><![CDATA[h3. B. Solution
Using a publicly available data log, we read in the data for process

Extract only a selected fields

Write these fields to a file to be stored on HDFS

We prepare the table in which these fields will be converted to in HIVE in 3 steps
- Drop table if it exists
- Create table with fields defined
- Load data from file to the fields

Verify by extracting data from table]]></attr>
</RichTextNote>
<RichTextNote backgroundColor="FFFFFF" enabled="true" folded="false" fontSize="medium" height="384" id="Note4" textColor="000000" width="255" x="440" y="103">
<attr name="text"><![CDATA[h3. Important
Be sure to configure and set the correct drivers (*.JAR) for your HDFS connection in Outline view prior to running this example!!

Please also note that each Hadoop build requires a different set of jar support files - refer to Hadoop documentation to see which files you need.

Check the libraries in
Outline/Connections/HadoopLocal

For HIVE connection, please configure an JDBC connection and please be sure to download the correct JAR files

This example is tested with
Cloudera 5.6.0 distribution]]></attr>
</RichTextNote>
<RichTextNote backgroundColor="FFFFFF" enabled="true" folded="false" fontSize="medium" height="384" id="Note6" textColor="000000" width="248" x="694" y="103">
<attr name="text"><![CDATA[h3. Notes
The bundled data file is only a sample.

For performance testing you can download the full version (+500MB) here: 

[https://explore.data.gov/dataset/White-House-Visitor-Records-Requests/644b-gaut]]]></attr>
</RichTextNote>
<RichTextNote backgroundColor="FFFFE1" enabled="true" folded="false" fontSize="medium" height="332" id="Note0" textColor="000000" width="219" x="20" y="507">
<attr name="text"><![CDATA[h3. Note









- the packaged public data file is a sample. please download the full version (+500MB) here:
 
[https://explore.data.gov/dataset/White-House-Visitor-Records-Requests/644b-gaut]]]></attr>
</RichTextNote>
<RichTextNote backgroundColor="FFFFE1" enabled="true" folded="false" fontSize="medium" height="413" id="Note1" textColor="000000" width="273" x="670" y="507">
<attr name="text"><![CDATA[h3. IMPORTANT NOTE









- the Hadoop server version used in this example is Cloudera 5.6.0

- the jar files used in this HDFS connection are:
+ avro-1.7.6-cdh5.6.0.jar
+ guava-15.0.jar
+ hadoop-auth-2.6.0-cdh5.6.0.jar
+ hadoop-common-2.6.0-cdh5.6.0.jar
+ hadoop-hdfs-2.6.0-cdh5.6.0.jar
+ htrace-core4-4.0.1-incubating.jar
+ protobuf-java-2.5.0.jar
+ servlet-api-3.0.jar

- please download the correct jar files for your Hadoop build]]></attr>
</RichTextNote>
<RichTextNote backgroundColor="FFFFE1" enabled="true" folded="false" fontSize="medium" height="404" id="Note7" textColor="000000" width="261" x="20" y="925">
<attr name="text"><![CDATA[h3. IMPORTANT NOTE







- the Hadoop server version used in this example is Cloudera 5.6.0

- the jar files used in this HIVE connection are:
+ hive-exec-1.1.0-cdh5.6.0.jar
+ hive-jdbc-1.1.0-cdh5.6.0.jar
+ hive-metastore-1.1.0-cdh5.6.0.jar
+ hive-service-1.1.0-cdh5.6.0.jar
+ libfb303-0.9.2.jar
+ slf4j-api-1.7.5.jar
+ slf4j-log4j12-1.7.5.jar

- for HIVE connection, please configure an JDBC connection and please be sure to download the correct jar files]]></attr>
</RichTextNote>
<Dictionary/>
</Global>
<Phase number="0">
<Node guiName="Extract Fields" guiX="360" guiY="562" id="EXTRACT_FIELDS" type="REFORMAT">
<attr name="transform"><![CDATA[//#CTL2

// Transforms input record into output record.
function integer transform() {
	$out.0.NAMELAST = $in.0.NAMELAST;
	$out.0.NAMEFIRST = $in.0.NAMEFIRST;
	$out.0.NAMEMID = $in.0.NAMEMID;
	$out.0.APPT_START_DATE = $in.0.APPT_START_DATE;
	$out.0.MEETING_LOC = $in.0.MEETING_LOC;
	$out.0.MEETING_ROOM = $in.0.MEETING_ROOM;

	return OK;
}

// Called during component initialization.
// function boolean init() {}

// Called during each graph run before the transform is executed. May be used to allocate and initialize resources
// required by the transform. All resources allocated within this method should be released
// by the postExecute() method.
// function void preExecute() {}

// Called only if transform() throws an exception.
// function integer transformOnError(string errorMessage, string stackTrace) {}

// Called during each graph run after the entire transform was executed. Should be used to free any resources
// allocated within the preExecute() method.
// function void postExecute() {}

// Called to return a user-defined error message when an error occurs.
// function string getMessage() {}
]]></attr>
</Node>
<Node dataPolicy="lenient" fileURL="zip:(${DATAIN_DIR}/White_House_Visitor_Records_Requests.zip)#White_House_Visitor_Records_Requests.csv" guiName="Read Log" guiX="52" guiY="562" id="READ_LOG" skipRows="1" type="DATA_READER"/>
<Node fileURL="hdfs://LOCAL_HADOOP/tmp/bigdata_examples/visitors_log.csv" guiName="Write to HDFS Storage" guiX="727" guiY="562" id="WRITE_TO_HDFS_STORAGE" type="DATA_WRITER"/>
<Edge debugMode="true" fromNode="EXTRACT_FIELDS:0" guiBendpoints="" guiRouter="Manhattan" id="Edge1" inPort="Port 0 (in)" metadata="Metadata1" outPort="Port 0 (out)" toNode="WRITE_TO_HDFS_STORAGE:0"/>
<Edge debugMode="true" fromNode="READ_LOG:0" guiBendpoints="" guiRouter="Manhattan" id="Edge0" inPort="Port 0 (in)" metadata="Metadata0" outPort="Port 0 (output)" toNode="EXTRACT_FIELDS:0"/>
</Phase>
<Phase number="1">
<Node dbConnection="LOCAL_HIVE" enabled="enabled" guiName="Drop Table VisitorsLogTable [HIVE]" guiX="39" guiY="980" id="DROP_TABLE_VISITORS_LOG_TABLE_HIVE" inTransaction="one" type="DB_EXECUTE">
<attr name="sqlQuery"><![CDATA[DROP TABLE IF EXISTS VisitorsLogTable]]></attr>
</Node>
</Phase>
<Phase number="2">
<Node dbConnection="LOCAL_HIVE" enabled="enabled" guiName="Create Table VisitorsLogTable [HIVE]" guiX="360" guiY="980" id="CREATE_TABLE_VISITORS_LOG_TABLE_HIVE" inTransaction="one" type="DB_EXECUTE">
<attr name="sqlQuery"><![CDATA[CREATE TABLE IF NOT EXISTS VisitorsLogTable (NAME_LAST STRING, NAME_FIRST STRING, NAME_MID STRING, APPT_START_DATE STRING, MEETING_LOC STRING, MEETING_ROOM STRING)
ROW FORMAT DELIMITED FIELDS TERMINATED BY '|'
STORED AS TEXTFILE]]></attr>
</Node>
</Phase>
<Phase number="3">
<Node dbConnection="LOCAL_HIVE" enabled="enabled" guiName="Convert HDFS File to VisitorsLogTable [HIVE]" guiX="668" guiY="980" id="CONVERT_HDFS_FILE_TO_VISITORS_LOG_TABLE_HIVE" inTransaction="one" type="DB_EXECUTE">
<attr name="sqlQuery"><![CDATA[LOAD DATA INPATH '/tmp/bigdata_examples/visitors_log.csv' OVERWRITE INTO TABLE VisitorsLogTable;]]></attr>
</Node>
</Phase>
<Phase number="4">
<Node enabled="enabled" guiName="Complete" guiX="711" guiY="1357" id="COMPLETE" type="SUCCESS"/>
<Node dbConnection="LOCAL_HIVE" enabled="enabled" guiName="Read Data from VisitorsLogTable [HIVE]" guiX="20" guiY="1357" id="READ_DATA_FROM_VISITORS_LOG_TABLE_HIVE" type="DB_INPUT_TABLE">
<attr name="sqlQuery"><![CDATA[select * from visitorslogtable]]></attr>
</Node>
<Edge debugMode="true" fromNode="READ_DATA_FROM_VISITORS_LOG_TABLE_HIVE:0" guiBendpoints="" guiRouter="Manhattan" id="Edge3" inPort="Port 0 (in)" metadata="Metadata1" outPort="Port 0 (out)" toNode="COMPLETE:0"/>
</Phase>
</Graph>
