<?xml version="1.0" encoding="UTF-8"?><Graph author="Wesley" created="Wed Feb 20 11:21:19 CET 2013" guiVersion="3.4.0.M2" id="1361360543511" licenseType="Commercial" modified="Mon Mar 18 13:53:28 CET 2013" modifiedBy="Pavel" name="ProcessLog_CloverETL" nature="jobflow" revision="1.75" showComponentDetails="true">
<Global>
<Metadata id="ExecuteGraph_RunStatus2">
<Record fieldDelimiter="|" name="ExecuteGraph_RunStatus" recordDelimiter="\n" type="delimited">
<Field name="runId" type="long"/>
<Field name="originalJobURL" type="string"/>
<Field format="yyyy-MM-dd HH:mm:ss" name="startTime" type="date"/>
<Field format="yyyy-MM-dd HH:mm:ss" name="endTime" type="date"/>
<Field name="duration" type="long"/>
<Field name="status" type="string"/>
<Field name="errException" type="string"/>
<Field name="errMessage" type="string"/>
<Field name="errComponent" type="string"/>
<Field name="errComponentType" type="string"/>
</Record>
</Metadata>
<Connection config="${CONN_DIR}/Hadoop-CDH-3u5.cfg" id="CDH3" type="HADOOP"/>
<Connection config="${CONN_DIR}/Hadoop-CDH-4.1.2.cfg" id="CDH4" type="HADOOP"/>
<Property fileURL="workspace.prm" id="GraphParameter0"/>
<Note alignment="1" backgroundColorB="255" backgroundColorG="255" backgroundColorR="255" enabled="true" folded="false" height="290" id="Note6" textColorB="0" textColorG="0" textColorR="0" textFontSize="8" title="MapReduce" titleColorB="0" titleColorG="0" titleColorR="0" titleFontSize="10" width="233" x="721" y="122">
<attr name="text"><![CDATA[
MapReduce job JAR:
lib/hadoop/mapreduce/UniqueVisits.jar

MapReduce source (Eclipse project)
src/]]></attr>
</Note>
<Note alignment="1" backgroundColorB="255" backgroundColorG="255" backgroundColorR="255" enabled="true" folded="false" height="290" id="Note4" textColorB="0" textColorG="0" textColorR="0" textFontSize="8" title="Configuration" titleColorB="0" titleColorG="0" titleColorR="0" titleFontSize="10" width="233" x="489" y="122">
<attr name="text"><![CDATA[
Before running the job you need to setup the Hadoop HDFS and Hive connections in underlying jobs.

The necessary Hive and Hadoop libraries are located in "lib" directory of this project

Hadoop HDFS+MapRed:
- CDH-3u5: lib/hadoop/cdh3u5/*.jar 
- CDH-4.1.2: lib/hadoop/cdh-412/*jar

]]></attr>
</Note>
<Note alignment="1" backgroundColorB="255" backgroundColorG="255" backgroundColorR="255" enabled="true" folded="false" height="290" id="Note5" textColorB="0" textColorG="0" textColorR="0" textFontSize="8" title="Hadoop MapReduce approach" titleColorB="0" titleColorG="0" titleColorR="0" titleFontSize="10" width="233" x="257" y="122">
<attr name="text"><![CDATA[
The solution relies on Hadoop map-reduce and takes the following steps:

Step 1: Parse the log file on local disks, extract the (year+month, ip) pairs and upload it to to HDFS

Step 2: Invoke map-reduce and count unique visitors utilizing the secondary sort. Map-reduce job stores its output as a text file on HDFS.

Step 3: Get the output file from HDFS to local disk.

Step 4: Sorts the output file and generate an Excel report.]]></attr>
</Note>
<Note alignment="1" backgroundColorB="96" backgroundColorG="255" backgroundColorR="96" enabled="true" folded="false" height="151" id="Note0" textColorB="0" textColorG="0" textColorR="0" textFontSize="8" title="Call MapReduce and get results" titleColorB="0" titleColorG="0" titleColorR="0" titleFontSize="10" width="534" x="243" y="448"/>
<Note alignment="2" backgroundColorB="64" backgroundColorG="64" backgroundColorR="64" enabled="true" folded="false" height="84" id="Note3" textColorB="255" textColorG="255" textColorR="255" textFontSize="10" title="Big Data - Processing Web Access Log (Unique Visitors):  Hadoop MapReduce" titleColorB="255" titleColorG="255" titleColorR="255" titleFontSize="13" width="929" x="25" y="39">
<attr name="text"><![CDATA[Report the number of unique visitors per month from a potentially huge web access log using different methods.
(CloverETL, Hadoop HIVE, and Hadoop MapReduce)]]></attr>
</Note>
<Note alignment="1" backgroundColorB="255" backgroundColorG="255" backgroundColorR="255" enabled="true" folded="false" height="290" id="Note2" textColorB="0" textColorG="0" textColorR="0" textFontSize="8" title="Scenario" titleColorB="64" titleColorG="64" titleColorR="64" titleFontSize="10" width="233" x="25" y="122">
<attr name="text"><![CDATA[
Web servers under heavy load can generate web access logs in orders of tens or hundreds of gigabytes per day.

Preparing such data for analytics in a timely basis is crucial to fast operating businesses.

In this example we demonstrate how to produce a simple "uniques per month" report from a standard Apache access_log file.
]]></attr>
</Note>
<Dictionary/>
</Global>
<Phase number="0">
<Node clearOutputDir="true" enabled="enabled" groupingComparatorClass="com.cloveretl.bigdata.example.weblog.GroupByMonthComparator" guiName="Count Unique Visitors using MapReduce" guiX="263" guiY="502" hadoopConnectionId="CDH3" id="COUNT_UNIQUE_VISITORS_USING_MAP_REDUCE" inputFiles="/tmp/bigdata_examples/key-value-pairs" jarLocation="${LIB_DIR}/hadoop/mapreduce-job-definition/UniqueVisits.jar" jobAPIVersion="mapreduce" jobName="Unique Weblog IPs" mapperClass="com.cloveretl.bigdata.example.weblog.UniqueVisitsMapper_NewAPI" mapperOutKeyClass="com.cloveretl.bigdata.example.weblog.CompositeKey" mapperOutValueClass="org.apache.hadoop.io.Text" outKeyClass="org.apache.hadoop.io.Text" outValueClass="org.apache.hadoop.io.IntWritable" outputDirectory="/tmp/WebLogIPsResult" partitionerClass="com.cloveretl.bigdata.example.weblog.GroupByMonthPartitioner_NewAPI" reducerClass="com.cloveretl.bigdata.example.weblog.UniqueVisitsReducer_NewAPI" sortingComparatorClass="com.cloveretl.bigdata.example.weblog.CompositeKeyComparator" type="EXECUTE_MAPREDUCE"/>
<Node enabled="enabled" guiName="Download Results from HDFS" guiX="562" guiY="502" id="DOWNLOAD_RESULTS_FROM_HDFS" jobURL="${GRAPH_DIR}/HadoopMapReduce-CountVisits.grf" type="EXECUTE_GRAPH"/>
<Node enabled="enabled" guiName="Generate Report" guiX="826" guiY="502" id="GENERATE_REPORT" jobURL="${GRAPH_DIR}/GenerateReport.grf" type="EXECUTE_GRAPH"/>
<Node enabled="enabled" guiName="Upload Inputs to HDFS" guiX="25" guiY="502" id="UPLOAD_INPUTS_TO_HDFS" jobURL="${GRAPH_DIR}/PrepareInputData.grf" type="EXECUTE_GRAPH">
<attr name="outputMapping"><![CDATA[//#CTL2

// Transforms input record into output record.
function integer transform() {
	$out.0.runId = $in.1.runId;
	$out.0.originalJobURL = $in.1.originalJobURL;
	$out.0.startTime = $in.1.startTime;
	$out.0.endTime = $in.1.endTime;
	$out.0.duration = $in.1.duration;
	$out.0.status = $in.1.status;
	$out.0.errException = $in.1.errException;
	$out.0.errMessage = $in.1.errMessage;
	$out.0.errComponent = $in.1.errComponent;
	$out.0.errComponentType = $in.1.errComponentType;

	return ALL;
}

// Called during component initialization.
// function boolean init() {}

// Called during each graph run before the transform is executed. May be used to allocate and initialize resources
// required by the transform. All resources allocated within this method should be released
// by the postExecute() method.
// function void preExecute() {}

// Called only if transform() throws an exception.
// function integer transformOnError(string errorMessage, string stackTrace) {}

// Called during each graph run after the entire transform was executed. Should be used to free any resources
// allocated within the preExecute() method.
// function void postExecute() {}

// Called to return a user-defined error message when an error occurs.
// function string getMessage() {}
]]></attr>
</Node>
<Edge debugMode="true" fromNode="COUNT_UNIQUE_VISITORS_USING_MAP_REDUCE:0" guiBendpoints="" guiRouter="Manhattan" id="Edge1" inPort="Port 0 (in)" metadata="ExecuteGraph_RunStatus2" outPort="Port 0 (out)" toNode="DOWNLOAD_RESULTS_FROM_HDFS:0"/>
<Edge debugMode="true" fromNode="DOWNLOAD_RESULTS_FROM_HDFS:0" guiBendpoints="" guiRouter="Manhattan" id="Edge0" inPort="Port 0 (in)" metadata="ExecuteGraph_RunStatus2" outPort="Port 0 (out)" toNode="GENERATE_REPORT:0"/>
<Edge debugMode="true" fromNode="UPLOAD_INPUTS_TO_HDFS:0" guiBendpoints="" guiRouter="Manhattan" id="Edge2" inPort="Port 0 (in)" metadata="ExecuteGraph_RunStatus2" outPort="Port 0 (out)" toNode="COUNT_UNIQUE_VISITORS_USING_MAP_REDUCE:0"/>
</Phase>
</Graph>
