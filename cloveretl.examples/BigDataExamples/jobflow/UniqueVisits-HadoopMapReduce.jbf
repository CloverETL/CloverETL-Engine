<?xml version="1.0" encoding="UTF-8"?>
<Graph author="Wesley" created="Wed Feb 20 11:21:19 CET 2013" guiVersion="0.0.0.devel" id="1361360543511" licenseCode="Commercial Devel" licenseType="Commercial" modified="Tue Mar 25 15:58:05 CET 2014" modifiedBy="User" name="ProcessLog_CloverETL" nature="jobflow" revision="1.107" showComponentDetails="true">
<Global>
<Connection config="${CONN_DIR}/Hadoop-CDH-5.6.0.cfg" id="CDH5" type="HADOOP"/>
<GraphParameters>
<GraphParameterFile fileURL="hadoop.prm"/>
<GraphParameterFile fileURL="workspace.prm"/>
</GraphParameters>
<RichTextNote backgroundColor="60FF60" enabled="true" folded="false" fontSize="medium" height="172" id="Note0" textColor="000000" width="547" x="319" y="501">
<attr name="text"><![CDATA[h3. Call MapReduce and get results
]]></attr>
</RichTextNote>
<RichTextNote backgroundColor="404040" enabled="true" folded="false" fontSize="medium" height="107" id="Note3" textColor="FFFFFF" width="929" x="25" y="16">
<attr name="text"><![CDATA[h3. Big Data - Processing Web Access Log (Unique Visitors):  Hadoop MapReduce
Report the number of unique visitors per month from a potentially huge web access log using different methods.
(CloverETL, Hadoop HIVE, Hadoop MapReduce, and MongoDB)]]></attr>
</RichTextNote>
<RichTextNote backgroundColor="FFFFFF" enabled="true" folded="false" fontSize="medium" height="365" id="Note2" textColor="000000" width="215" x="25" y="122">
<attr name="text"><![CDATA[h3. Scenario

Web servers under heavy load can generate web access logs in orders of tens or hundreds of gigabytes per day.

Preparing such data for analytics in a timely basis is crucial to fast operating businesses.

In this example we demonstrate how to produce a simple "uniques per month" report from a standard Apache access_log file.
]]></attr>
</RichTextNote>
<RichTextNote backgroundColor="FFFFFF" enabled="true" folded="false" fontSize="medium" height="365" id="Note5" textColor="000000" width="270" x="239" y="122">
<attr name="text"><![CDATA[h3. Hadoop MapReduce approach

The solution relies on Hadoop map-reduce and takes the following steps:

Step 1: Parse the log file on local disks, extract the (year+month, ip) pairs and upload it to to HDFS

Step 2: Invoke map-reduce and count unique visitors utilizing the secondary sort. Map-reduce job stores its output as a text file on HDFS.

Step 3: Get the output file from HDFS to local disk.

Step 4: Sorts the output file and generate an Excel report.]]></attr>
</RichTextNote>
<RichTextNote backgroundColor="FFFFFF" enabled="true" folded="false" fontSize="medium" height="365" id="Note4" textColor="000000" width="241" x="508" y="122">
<attr name="text"><![CDATA[h3. Configuration

Before running the job you need to setup the Hadoop HDFS+MapReduce connection in underlying jobs.

The necessary Hadoop libraries are located in "lib" directory of this project

Hadoop HDFS+MapRed:
- CDH-3u5: lib/hadoop/cdh3u5/*.jar 
- CDH-4.1.2: lib/hadoop/cdh-412/*jar
- CDH-5.6.0: lib/hadoop/cdh-560/*jar]]></attr>
</RichTextNote>
<RichTextNote backgroundColor="FFFFFF" enabled="true" folded="false" fontSize="medium" height="365" id="Note6" textColor="000000" width="206" x="748" y="122">
<attr name="text"><![CDATA[h3. MapReduce

MapReduce job JAR:
lib/hadoop/mapreduce/UniqueVisits.jar

MapReduce source (Eclipse project)
src/]]></attr>
</RichTextNote>
<Dictionary/>
</Global>
<Phase number="0">
<Node enabled="enabled" guiName="Check required parameters" guiX="-59" guiY="555" id="CHECK_REQUIRED_PARAMETERS" jobURL="${GRAPH_DIR}/CheckParameters-MapReduce.grf" type="EXECUTE_GRAPH">
<attr name="errorMapping"><![CDATA[//#CTL2

// Transforms input record into output record.
function integer transform() {
	$out.1.errMessage = $in.1.errMessage;

	return ALL;
}

// Called during component initialization.
// function boolean init() {}

// Called during each graph run before the transform is executed. May be used to allocate and initialize resources
// required by the transform. All resources allocated within this method should be released
// by the postExecute() method.
// function void preExecute() {}

// Called only if transform() throws an exception.
// function integer transformOnError(string errorMessage, string stackTrace) {}

// Called during each graph run after the entire transform was executed. Should be used to free any resources
// allocated within the preExecute() method.
// function void postExecute() {}

// Called to return a user-defined error message when an error occurs.
// function string getMessage() {}
]]></attr>
</Node>
<Node clearOutputDir="true" enabled="enabled" groupingComparatorClass="com.cloveretl.bigdata.example.weblog.GroupByMonthComparator" guiName="Count Unique Visitors using MapReduce" guiX="339" guiY="555" hadoopConnectionId="CDH5" id="COUNT_UNIQUE_VISITORS_USING_MAP_REDUCE" inputFiles="/tmp/bigdata_examples/key-value-pairs" jarLocation="${LIB_DIR}/hadoop/mapreduce-job-definition/UniqueVisits.jar" jobAPIVersion="mapreduce" jobName="Unique Weblog IPs" mapperClass="com.cloveretl.bigdata.example.weblog.UniqueVisitsMapper_NewAPI" mapperOutKeyClass="com.cloveretl.bigdata.example.weblog.CompositeKey" mapperOutValueClass="org.apache.hadoop.io.Text" outKeyClass="org.apache.hadoop.io.Text" outValueClass="org.apache.hadoop.io.IntWritable" outputDirectory="/tmp/WebLogIPsResult" partitionerClass="com.cloveretl.bigdata.example.weblog.GroupByMonthPartitioner_NewAPI" reducerClass="com.cloveretl.bigdata.example.weblog.UniqueVisitsReducer_NewAPI" sortingComparatorClass="com.cloveretl.bigdata.example.weblog.CompositeKeyComparator" type="EXECUTE_MAPREDUCE"/>
<Node enabled="enabled" guiName="Download Results from HDFS" guiX="638" guiY="555" id="DOWNLOAD_RESULTS_FROM_HDFS" jobURL="${GRAPH_DIR}/HadoopMapReduce-CountVisits.grf" type="EXECUTE_GRAPH"/>
<Node enabled="enabled" guiName="Generate Report" guiX="902" guiY="555" id="GENERATE_REPORT" jobURL="${GRAPH_DIR}/GenerateReport.grf" type="EXECUTE_GRAPH"/>
<Node enabled="enabled" guiName="Required Parameters Missing" guiX="55" guiY="682" id="REQUIRED_PARAMETERS_MISSING" type="FAIL">
<attr name="mapping"><![CDATA[//#CTL2

// Transforms input record into output record.
function integer transform() {
	$out.0.errorMessage = $in.0.errMessage;

	return ALL;
}

// Called during component initialization.
// function boolean init() {}

// Called during each graph run before the transform is executed. May be used to allocate and initialize resources
// required by the transform. All resources allocated within this method should be released
// by the postExecute() method.
// function void preExecute() {}

// Called only if transform() throws an exception.
// function integer transformOnError(string errorMessage, string stackTrace) {}

// Called during each graph run after the entire transform was executed. Should be used to free any resources
// allocated within the preExecute() method.
// function void postExecute() {}

// Called to return a user-defined error message when an error occurs.
// function string getMessage() {}
]]></attr>
</Node>
<Node enabled="enabled" guiName="Upload Inputs to HDFS" guiX="142" guiY="555" id="UPLOAD_INPUTS_TO_HDFS" jobURL="${GRAPH_DIR}/PrepareInputData.grf" type="EXECUTE_GRAPH">
<attr name="outputMapping"><![CDATA[//#CTL2

// Transforms input record into output record.
function integer transform() {
	$out.0.runId = $in.1.runId;
	$out.0.originalJobURL = $in.1.originalJobURL;
	$out.0.startTime = $in.1.startTime;
	$out.0.endTime = $in.1.endTime;
	$out.0.duration = $in.1.duration;
	$out.0.status = $in.1.status;
	$out.0.errException = $in.1.errException;
	$out.0.errMessage = $in.1.errMessage;
	$out.0.errComponent = $in.1.errComponent;
	$out.0.errComponentType = $in.1.errComponentType;

	return ALL;
}

// Called during component initialization.
// function boolean init() {}

// Called during each graph run before the transform is executed. May be used to allocate and initialize resources
// required by the transform. All resources allocated within this method should be released
// by the postExecute() method.
// function void preExecute() {}

// Called only if transform() throws an exception.
// function integer transformOnError(string errorMessage, string stackTrace) {}

// Called during each graph run after the entire transform was executed. Should be used to free any resources
// allocated within the preExecute() method.
// function void postExecute() {}

// Called to return a user-defined error message when an error occurs.
// function string getMessage() {}
]]></attr>
</Node>
<Edge fromNode="CHECK_REQUIRED_PARAMETERS:0" guiBendpoints="" guiRouter="Manhattan" id="Edge4" inPort="Port 0 (in)" outPort="Port 0 (out)" toNode="UPLOAD_INPUTS_TO_HDFS:0"/>
<Edge fromNode="CHECK_REQUIRED_PARAMETERS:1" guiBendpoints="" guiRouter="Manhattan" id="Edge3" inPort="Port 0 (in)" outPort="Port 1 (error)" toNode="REQUIRED_PARAMETERS_MISSING:0"/>
<Edge debugMode="true" fromNode="COUNT_UNIQUE_VISITORS_USING_MAP_REDUCE:0" guiBendpoints="" guiRouter="Manhattan" id="Edge1" inPort="Port 0 (in)" outPort="Port 0 (out)" toNode="DOWNLOAD_RESULTS_FROM_HDFS:0"/>
<Edge debugMode="true" fromNode="DOWNLOAD_RESULTS_FROM_HDFS:0" guiBendpoints="" guiRouter="Manhattan" id="Edge0" inPort="Port 0 (in)" outPort="Port 0 (out)" toNode="GENERATE_REPORT:0"/>
<Edge debugMode="true" fromNode="UPLOAD_INPUTS_TO_HDFS:0" guiBendpoints="" guiRouter="Manhattan" id="Edge2" inPort="Port 0 (in)" outPort="Port 0 (out)" toNode="COUNT_UNIQUE_VISITORS_USING_MAP_REDUCE:0"/>
</Phase>
</Graph>
