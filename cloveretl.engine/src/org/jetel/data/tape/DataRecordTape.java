/*
*    jETeL/Clover - Java based ETL application framework.
*    Copyright (C) 2002-05  David Pavlis <david_pavlis@hotmail.com>
*    
*    This library is free software; you can redistribute it and/or
*    modify it under the terms of the GNU Lesser General Public
*    License as published by the Free Software Foundation; either
*    version 2.1 of the License, or (at your option) any later version.
*    
*    This library is distributed in the hope that it will be useful,
*    but WITHOUT ANY WARRANTY; without even the implied warranty of
*    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU    
*    Lesser General Public License for more details.
*    
*    You should have received a copy of the GNU Lesser General Public
*    License along with this library; if not, write to the Free Software
*    Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
*
*/
package org.jetel.data.tape;

import java.io.File;
import java.io.IOException;
import java.io.RandomAccessFile;
import java.nio.BufferOverflowException;
import java.nio.ByteBuffer;
import java.nio.channels.ClosedChannelException;
import java.nio.channels.FileChannel;
import java.util.ArrayList;
import java.util.Iterator;
import java.util.List;

import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.jetel.data.DataRecord;
import org.jetel.data.Defaults;
import org.jetel.util.bytes.ByteBufferUtils;


/**
 * Data structure for storing records in chunks on local disk (in temporary file).<br>
 * When the data object is closed - the physical representation (the file) is removed - i.e.
 * no permanent storage is performed.<br>
 * Each chunk registers how many records is stored in it. The number
 * of chunks on tape(in file) is not limited. Records can be read only
 * sequentially, but particular chunk can be selected.<br><br>
 * <i>Usage:</i><br>
 * <code>
 * tape=new DataRecordTape();<br>
 * tape.open();<br>
 * tape.addDataChunk();<br>
 * ..loop.. tape.put(..data..);<br>
 * tape.addDataChunk();<br>
 * ..loop.. tape.put(..data..);<br>
 * tape.rewind();<br>
 * ..loop..tape.get();<br>
 * tape.nextChunk();<br>
 * ..loop..tape.get();<br>
 * tape.close();<br>
 * </code>
 * 
 * @author david
 * @since  20.1.2005
 *
 */
public class DataRecordTape {

    private FileChannel tmpFileChannel;
	private File tmpFile;
    private File tmpDirectory;
	private String tmpFileName;

    private boolean deleteOnExit;
    private boolean deleteOnStart;
    
	private List dataChunks;
	
	private ByteBuffer dataBuffer;

	private DataChunk currentDataChunk;
	private int currentDataChunkIndex;
    
	// size of BUFFER - used for push & shift operations
	private final static int DEFAULT_BUFFER_SIZE = Defaults.DEFAULT_INTERNAL_IO_BUFFER_SIZE; 

	// prefix of temporary file generated by system	
	private final static String TMP_FILE_PREFIX = ".fbufclv";
	//	 suffix of temporary file generated by system
	private final static String TMP_FILE_SUFFIX = ".tmp";
	private final static String TMP_FILE_MODE = "rw";

	static Log logger = LogFactory.getLog(DataRecordTape.class);

	/**
	 *  Constructor for the DataRecordTape object
	 *
	 *@param  tmpFileName      Name of the temp file or NULL (the system default temp directory and name will be used)
	 *@param  dataBufferSize   The size of internal in memory buffer.
     *                          If smaller than DEFAULT_BUFFER_SIZE, then default is used
	 */
	public DataRecordTape(String tmpFileName, int dataBufferSize, boolean deleteOnStart, boolean deleteOnExit) {
		this.tmpFileName = tmpFileName;
        this.deleteOnStart = deleteOnStart;
        this.deleteOnExit = deleteOnExit;
		dataChunks=new ArrayList();
		dataBuffer = ByteBuffer.allocateDirect(dataBufferSize > DEFAULT_BUFFER_SIZE ? dataBufferSize : DEFAULT_BUFFER_SIZE);
	}

    /**
     * Constructor.
     * @param tmpFileName
     * @param deleteOnExit
     */
    public DataRecordTape(String tmpFileName, boolean deleteOnStart, boolean deleteOnExit) {
        this(tmpFileName,DEFAULT_BUFFER_SIZE, deleteOnStart, deleteOnExit);
    }

	/**
	 *  Constructor for the DataRecordTape object
	 *
     *@param  tmpFileName      Name of the temp file or NULL (the system default temp directory and name will be used)
	 */
	public DataRecordTape(String tmpFileName) {
		this(tmpFileName,DEFAULT_BUFFER_SIZE, true, true);
	}

	/**
	 * Constructor for DataRecordTape - all parameters defaulted.
	 */
	public DataRecordTape(){
	    this(null,DEFAULT_BUFFER_SIZE, true, true);
	}

	/**
	 *  Opens buffer, creates temporary file.
	 *
	 *@exception  IOException  Description of Exception
	 *@since                   September 17, 2002
	 */
	public void open() throws IOException {
        if(tmpFileName == null)
            tmpFile = File.createTempFile(TMP_FILE_PREFIX, TMP_FILE_SUFFIX, tmpDirectory);
        else {
            tmpFile = new File(tmpFileName);
            if(deleteOnStart && tmpFile.exists()) {
                if (!tmpFile.delete()) {
                    throw new IOException("Can't delete TMP file: " + tmpFile.getAbsoluteFile());
                }
            }
            if(!deleteOnStart && !tmpFile.exists()) {
                throw new IOException("Temp file does not exist.");
            }
        }
        if(deleteOnExit) tmpFile.deleteOnExit();
        
		// we want the temp file be deleted on exit
		tmpFileChannel = new RandomAccessFile(tmpFile, TMP_FILE_MODE).getChannel();
       	currentDataChunkIndex=-1;
		currentDataChunk=null;
	}


	/**
	 *  Closes buffer, removes temporary file (is exists)
	 *
	 *@exception  IOException  Description of Exception
	 * @throws InterruptedException 
	 *@since                   September 17, 2002
	 */
	public void close() throws IOException, InterruptedException {
        if(deleteOnExit) {
            clear();
            tmpFileChannel.close();
            if (!tmpFile.delete()) {
                throw new IOException("Can't delete TMP file: " + tmpFile.getAbsoluteFile());
            }
        } else {
            tmpFileChannel.close();
        }
	}

	/**
	 * Flushes tape content to disk.
	 * 
	 * @throws IOException
	 * @throws InterruptedException 
	 */
	public void flush(boolean force) throws IOException, InterruptedException {
		try {
		    dataBuffer.flip();
		    tmpFileChannel.write(dataBuffer);
		    dataBuffer.clear();
		    //currentDataChunk.flushBuffer();
		    if (force){
		        tmpFileChannel.force(true);
		    }
		} catch (ClosedChannelException e) {
			throw new InterruptedException();
		}
	}

	/**
	 *  Rewinds the buffer and makes first chunk active. Next get operation returns first record stored in
	 * first chunk.
	 * @throws InterruptedException 
	 * @throws IOException 
	 *
	 *@since    September 19, 2002
	 */
	public void rewind() throws InterruptedException, IOException {
	    if (dataChunks.size()==0){
	        return;
	    }

	    try {
		    flush(true);
	    	tmpFileChannel.position(0);
	    	
		    currentDataChunkIndex=0;
		    currentDataChunk=(DataChunk)dataChunks.get(0);
		    currentDataChunk.rewind();
	    } catch (ClosedChannelException e) {
	    	throw new InterruptedException();
	    }
	}

	/**
	 * Clears the internal buffer.
	 * <p>
	 * This method should be used before storing additional data records after all data
	 * records stored on the tape were read.
	 * <p>
	 * <b>Code fragment:</b>
	 * <pre>
	 *   tape.addDataChunk();
	 *   REPEAT tape.put(record);
	 *
	 *   tape.rewind();
	 *   REPEAT tape.get(record);
	 *
	 *   tape.clearBuffer();
	 *   REPEAT tape.put(record);
	 * </pre>
	 */
	public void clearBuffer() {
		dataBuffer.clear();
	}

	/**
	 *  Clears the tape. All DataChunks are destroyed. Underlying 
	 * tmp file is truncated.
	 * @throws InterruptedException 
	 */
	public void clear() throws IOException, InterruptedException {
		try {
			dataChunks.clear();
			tmpFileChannel.truncate(0);
			tmpFileChannel.position(0);
			currentDataChunkIndex=-1;
			currentDataChunk=null;
		} catch (ClosedChannelException e) {
			throw new InterruptedException();
		}
	}

	/**
	 * Adds new data chunk to the tape and opens it.
	 * @return true if successful, otherwise false
	 * @throws InterruptedException 
	 * @throws IOException 
	 */
	public void addDataChunk() throws InterruptedException, IOException {
	    if (currentDataChunk==null){
            // add new data chunk
            DataChunk chunk=new DataChunk(tmpFileChannel,dataBuffer);
            dataChunks.add(chunk);
            currentDataChunkIndex=0;
            currentDataChunk=chunk;
	    } else {
	    	try {
	            // set file position to the end of file
	        	flush(true);
	            tmpFileChannel.position(tmpFileChannel.size());
	            // add new data chunk
	            DataChunk chunk=new DataChunk(tmpFileChannel,dataBuffer);
	            dataChunks.add(chunk);
	            currentDataChunkIndex++;
	            currentDataChunk=chunk;
	    	} catch (ClosedChannelException e) {
	    		throw new InterruptedException();
	    	}
	    }
	    dataBuffer.clear();
	}

	/**
	 * Sets next data chunk active. Next get() operation will return first record
	 * from the newly activated chunk. This method must be called after rewind()
	 * method, otherwise the result is not guaranteed.
	 * 
	 * @return true if next data chunk has been activated, otherwise false
	 * @throws InterruptedException 
	 * @throws IOException 
	 * @throws IOException 
	 */
	public boolean nextDataChunk() throws InterruptedException, IOException {
	    if (currentDataChunkIndex!=-1 && currentDataChunkIndex+1 < dataChunks.size()){
	        currentDataChunkIndex++;
	        currentDataChunk=(DataChunk)dataChunks.get(currentDataChunkIndex);
	        currentDataChunk.rewind();
		        
	        return true;
	    }else{
	        currentDataChunkIndex=-1;
			currentDataChunk=null;
	        return false;
	    }
	}
	
	
	public boolean setDataChunk(int order) throws InterruptedException, IOException {
	    if (order<dataChunks.size()){
	        currentDataChunk=(DataChunk)dataChunks.get(order);
	        currentDataChunkIndex=order;
	        currentDataChunk.rewind();
	        
	        return true;
	    }else{
	        currentDataChunkIndex=-1;
			currentDataChunk=null;
	        return false;
	    }
	    
	}
	
	/**
     * Returns number of chunks this tape contains.
     * 
	 * @return
	 * @since 1.2.2007
	 */
	public int getNumChunks(){
	    return dataChunks.size();
	}
    
    
    /**
     * For specified chunk number returns its
     * length (in bytes).
     * 
     * @param chunk
     * @return
     * @since 1.2.2007
     */
    public long getChunkLength(int chunk) {
        return ((DataChunk)dataChunks.get(chunk)).getLength();
    }
    
    /**
     * For specified chunk number returns how
     * many records it contains.
     * 
     * @param chunk
     * @return
     * @since 1.2.2007
     */
    public int getChunkRecNum(int chunk) {
        return ((DataChunk)dataChunks.get(chunk)).getNumRecords();
    }
	
	/**
	 * Stores data in current/active chunk. Must not be mixed with calls to
	 * get() method, otherwise the result is not guaranteed.
	 * 
	 * @param data buffer containig record's data
	 * @return
	 * @throws InterruptedException 
	 */
	public long put(ByteBuffer data) throws IOException, InterruptedException {
		if (currentDataChunk != null) {
	        return currentDataChunk.put(data);
		} else {
	        throw new RuntimeException("No DataChunk has been created !");
	    }
	}
    
    
    /**
     * Bulk-copy of data (1 record) from one tape to the other (directly)
     * 
     * @param source DataRecordTape from which to copy data 
     * @return new size of chunk or -1 in case of problem
     * @throws InterruptedException 
     */
    public long put(DataRecordTape sourceTape) throws IOException, InterruptedException{
        if (currentDataChunk != null) {
            if (sourceTape.currentDataChunk!=null){
                return currentDataChunk.put(sourceTape.currentDataChunk);
            }else{
                return -1;
            }
        } else {
            throw new RuntimeException("No DataChunk has been created !");
        }
    }
    
    public long putDirect(DataRecordTape sourceTape) throws IOException, InterruptedException {
    	if (currentDataChunk != null) {
            if (sourceTape.currentDataChunk!=null){
                return currentDataChunk.putDirect(sourceTape.currentDataChunk);
            }else{
                return -1;
            }
    	} else {
            throw new RuntimeException("No DataChunk has been created !");
        }
    }
	
	/**
	 * Stores data record in current/active chunk.
	 * 
	 * @param data
	 * @return
	 * @throws IOException
	 * @throws InterruptedException 
	 */
	public long put(DataRecord data) throws IOException, InterruptedException {
		if (currentDataChunk != null) {
	        return currentDataChunk.put(data);
		} else {
	        throw new RuntimeException("No DataChunk has been created !");
	    }
	}
	
	/**
	 * Fills buffer passed as an argument with data read from current data chunk.
	 * Must not be mixed with put() method calls, otherwise the result is not guaranteed.<br>
	 * The normal way of using this method is:<br>
	 * while(get(data)){
	 *   ... do something ...
	 * }
	 * @param data	buffer into which store data
	 * @return	true if success, otherwise false (chunk contains no more data).
	 * @throws InterruptedException 
	 */
	public boolean get(ByteBuffer data) throws IOException, InterruptedException {
	    if (currentDataChunk!=null){
	        return currentDataChunk.get(data);
	    }else{
	        return false;
	    }
	}
	
    /**
     * Reads again previously read record.
     * 
     * @param data
     * @return
     * @throws IOException
     * @since 27.2.2007
     */
    public boolean reget(ByteBuffer data) {
        if (currentDataChunk!=null){
            return currentDataChunk.reget(data);
        }else{
            return false;
        }
    }
    
	/**
	 * Reads data record from current chunk
	 * 
	 * @param data
	 * @return
	 * @throws IOException
	 * @throws InterruptedException  
	 */
	public boolean get(DataRecord data) throws IOException, InterruptedException {
	    if (currentDataChunk!=null){
	        return currentDataChunk.get(data);
	    }else{
	        return false;
	    }
	}
    
    /**
     * Reads again previously read record.
     * 
     * @param data
     * @return
     * @throws IOException
     * @since 27.2.2007
     */
    public boolean reget(DataRecord data) {
        if (currentDataChunk!=null){
            return currentDataChunk.reget(data);
        }else{
            return false;
        }
    }

	/* Returns String containing short summary of chunks stored on tape.
	 * 
	 * (non-Javadoc)
	 * @see java.lang.Object#toString()
	 */
	public String toString(){
	    StringBuffer buffer=new StringBuffer(160);
	    int index=0;
	    for (Iterator i=dataChunks.iterator();i.hasNext();){
	        buffer.append("Chunk #").append(index++);
	        buffer.append(((DataChunk)i.next()).toString());
	        buffer.append("\n");
	    }
	    return buffer.toString();
	}
	
	public void testConsistency() throws InterruptedException, IOException {
	    ByteBuffer buffer=ByteBuffer.allocateDirect(2048);
	    logger.info("Testing consistency...");

		rewind();
		
	    for(int i=0;i<getNumChunks();i++){
	        int counter=0;
	        try{
	            while(get(buffer)){
	                counter++;
	                buffer.clear();
	            }
		        if(!nextDataChunk()) break;
	        }catch(Exception ex){
	            logger.error("Problem with chunk: "+i+" record "+counter);
	            ex.printStackTrace();
	        }
	    }
	    logger.info("OK");
	}
	
	/**
	 * Helper class for storing data chunks. 
	 * @author david
	 * @since  20.1.2005
	 *
	 */
	private static class DataChunk{
	    //	size of integer variable used to keep record length
        // this is the maximum size, can be between 1 & 4 bytes
	    private final static int LEN_SIZE_SPECIFIER = 5;
	    ByteBuffer dataBuffer;
	    FileChannel tmpFileChannel;
	    long offsetStart;
	    long length;
	    int recordsRead;
	    int nRecords;
	    boolean canRead;
        int recordSize;
	    
	    private DataChunk(FileChannel channel,ByteBuffer buffer) throws InterruptedException, IOException{
	        tmpFileChannel=channel;
	        canRead=false;
	        dataBuffer=buffer;
	        try{
	            offsetStart=channel.position();
	    	} catch (ClosedChannelException e) {
	    		throw new InterruptedException();
	    	}
	        length=0;
	        nRecords=recordsRead=0;
	        dataBuffer.clear();
	    }
	    
	    long getLength(){
	        return length;
	    }
	    
	    int getNumRecords(){
	        return nRecords;
	    }
	    
	    void rewind() throws IOException, InterruptedException {
	    	try {
		        tmpFileChannel.position(offsetStart);
		        canRead=true;
		        recordsRead=0;
		        dataBuffer.clear();
		        tmpFileChannel.read(dataBuffer);
		        dataBuffer.flip();
	    	} catch (ClosedChannelException e) {
	    		throw new InterruptedException();
	    	}
	    }
	    
	    /**
		 *  Stores one data record into buffer / file.
		 *
		 *@param  recordBuffer             ByteBuffer containing record's data
		 *@exception  IOException  In case of IO failure
		 *@since                   September 17, 2002
		 *@return number of bytes in the chunk after saveing data
	     * @throws InterruptedException 
		 */
		long put(ByteBuffer recordBuffer) throws IOException, InterruptedException {
			recordSize = recordBuffer.remaining();
			final int lengthSize=ByteBufferUtils.lengthEncoded(recordSize);
			// check that internal buffer has enough space
			if ((recordSize + lengthSize) > dataBuffer.remaining()){
					flushBuffer();
				}
			
			try {
			    ByteBufferUtils.encodeLength(dataBuffer, recordSize);
                dataBuffer.put(recordBuffer);
			} catch (BufferOverflowException ex) {
				throw new IOException("Input Buffer is not big enough to accomodate data record !");
			}
			
			length+=(recordSize+ lengthSize);
			nRecords++;
			return length;
		}

       
        long put(DataChunk sourceChunk) throws IOException, InterruptedException {
            final ByteBuffer sourceDataBuffer=sourceChunk.dataBuffer;
            if(!sourceChunk.canRead){
                throw new IOException("Buffer has not been rewind !");
            }
            
            if (sourceChunk.nRecords > 0 && sourceChunk.recordsRead>=sourceChunk.nRecords){
                return -1;
            }
            //  check that internal buffer has enough data to read data size
            if (LEN_SIZE_SPECIFIER > sourceDataBuffer.remaining()){
                sourceChunk.reloadBuffer();
                if(sourceDataBuffer.remaining() == 0) return -1;
            }
            recordSize = ByteBufferUtils.decodeLength(sourceDataBuffer);
            
            //  check that internal buffer has enough data to read data record
            if (recordSize > sourceDataBuffer.remaining()){
                sourceChunk.reloadBuffer();
                if(recordSize > sourceDataBuffer.remaining()) return -1;
            }
            
            int oldLimit = sourceDataBuffer.limit();
            sourceDataBuffer.limit(sourceDataBuffer.position() + recordSize);
        
            //write it here         
            final int lengthSize=ByteBufferUtils.lengthEncoded(recordSize);
            // check that internal buffer has enough space
            if ((recordSize + lengthSize) > dataBuffer.remaining()){
                    flushBuffer();
                }
            
            try {
                ByteBufferUtils.encodeLength(dataBuffer, recordSize);
                dataBuffer.put(sourceDataBuffer);
            } catch (BufferOverflowException ex) {
                throw new IOException("Input Buffer is not big enough to accomodate data record !");
            }
            
            // end write 
            sourceDataBuffer.limit(oldLimit);
            length+=(recordSize+ lengthSize);
            nRecords++;
            return length;            
        }
        
        
        /**
         * This operation copies directly data from source chunk's buffer
         * into this chunk. <br>It assumes that get() operation on source chunk
         * was performed previously and source chunk's buffer contains the whole record<br>
         * 
         * @param sourceChunk
         * @return
         * @throws IOException
         * @throws InterruptedException 
         * @since 28.2.2007
         */
        long putDirect(DataChunk sourceChunk) throws IOException, InterruptedException {
            final ByteBuffer sourceDataBuffer=sourceChunk.dataBuffer;
            final int sourceRecSize=sourceChunk.recordSize;
            sourceDataBuffer.reset(); //we are re-getting data
          
            //  check that internal buffer has enough data to read data size
            final int lengthSize=ByteBufferUtils.lengthEncoded(sourceRecSize)+sourceRecSize;
            if (lengthSize > dataBuffer.remaining()){
                flushBuffer();
                if(lengthSize > dataBuffer.remaining()) return -1;
            }
            
            int oldLimit = sourceDataBuffer.limit();
            sourceDataBuffer.limit(sourceDataBuffer.position() + sourceRecSize);
        
            //write it here         
            try {
                ByteBufferUtils.encodeLength(dataBuffer, sourceRecSize);
                dataBuffer.put(sourceDataBuffer);
            } catch (BufferOverflowException ex) {
                throw new IOException("Input Buffer is not big enough to accomodate data record !");
            }
            
            // end write 
            sourceDataBuffer.limit(oldLimit);
            length+=lengthSize;
            nRecords++;
            return length;            
        }
        
        
		 /**
		  * Stores one data record into buffer / file.
		  * 
		 * @param data	DataRecord to be stored
		 *@return number of bytes in the chunk after saving data
		 * @throws IOException
		 * @throws InterruptedException 
		 */
		long put(DataRecord data) throws IOException, InterruptedException {
				recordSize = data.getSizeSerialized();
                final int lengthSize=ByteBufferUtils.lengthEncoded(recordSize);
				// check that internal buffer has enough space
				if ((recordSize + lengthSize) > dataBuffer.remaining()){
						flushBuffer();
					}
				
				try {
                    ByteBufferUtils.encodeLength(dataBuffer, recordSize);
					data.serialize(dataBuffer);
				} catch (BufferOverflowException ex) {
					throw new IOException("Input Buffer is not big enough to accomodate data record !");
				}
				
				length+=(recordSize+ lengthSize);
				nRecords++;
				return length;
			}

		/**
		 *  Returns next record from the buffer - FIFO order.
		 *
		 *@param  recordBuffer             ByteBuffer into which store data
		 *@return                  ByteBuffer populated with record's data or NULL if
		 *      no more record can be retrieved
		 *@exception  IOException  Description of Exception
		 * @throws InterruptedException 
		 *@since                   September 17, 2002
		 */
		 boolean get(ByteBuffer recordBuffer) throws IOException, InterruptedException {
			if(!canRead){
				throw new IOException("Buffer has not been rewind !");
			}
			
			if (nRecords > 0 && recordsRead>=nRecords){
			    return false;
			}
			//	check that internal buffer has enough data to read data size
			if (LEN_SIZE_SPECIFIER > dataBuffer.remaining()){
			    reloadBuffer();
			    if(dataBuffer.remaining() == 0) return false;
			}
			recordSize = ByteBufferUtils.decodeLength(dataBuffer);
			
			//	check that internal buffer has enough data to read data record
			if (recordSize > dataBuffer.remaining()){
			    reloadBuffer();
			    if(recordSize > dataBuffer.remaining()) return false;
			}
			int oldLimit = dataBuffer.limit();
            dataBuffer.mark(); //could be used later in reget method
			dataBuffer.limit(dataBuffer.position() + recordSize);
            recordBuffer.clear();
			recordBuffer.put(dataBuffer);
			recordBuffer.flip();
			dataBuffer.limit(oldLimit);
			
			recordsRead++;
			return true;
		}

         /**
          * Read again previously read record. Use caution when calling this
          * method as it lifts most of the safety checks. Should be used
          * only immediately after successful get(ByteBuffer) call
          * 
         * @param recordBuffer
         * @return
         * @throws IOException
         * @since 27.2.2007
         */
        boolean reget(ByteBuffer recordBuffer) {
                dataBuffer.reset();
                int oldLimit = dataBuffer.limit();
                dataBuffer.limit(dataBuffer.position() + recordSize);
                recordBuffer.clear();
                recordBuffer.put(dataBuffer);
                recordBuffer.flip();
                dataBuffer.limit(oldLimit);
                return true;
            }
         
         
//         protected ByteBuffer bulkGetStart() throws IOException {
//                final int recordSize;
//                if(!canRead){
//                    throw new IOException("Buffer has not been rewind !");
//                }
//                
//                if (nRecords > 0 && recordsRead>=nRecords){
//                    return null;
//                }
//                //  check that internal buffer has enough data to read data size
//                if (LEN_SIZE_SPECIFIER > dataBuffer.remaining()){
//                    reloadBuffer();
//                    if(LEN_SIZE_SPECIFIER > dataBuffer.remaining()) return null;
//                }
//                recordSize = ByteBufferUtils.decodeLength(dataBuffer);
//                
//                //  check that internal buffer has enough data to read data record
//                if (recordSize > dataBuffer.remaining()){
//                    reloadBuffer();
//                    if(recordSize > dataBuffer.remaining()) return null;
//                }
//                int oldLimit = dataBuffer.limit();
//                dataBuffer.limit(dataBuffer.position() + recordSize);
//                //write it here
//                
//                dataBuffer.limit(oldLimit);
//                recordsRead++;
//                return dataBuffer;
//            }

       
         
         
		 /**
		  * Returns next record from the buffer - FIFO order.
		 * @param data	DataRecord into which load the data
		 * @return
		 * @throws IOException
		 * @throws InterruptedException 
		 */
		boolean get(DataRecord data) throws IOException, InterruptedException {
				if(!canRead){
					throw new IOException("Buffer has not been rewind !");
				}
				
				if (nRecords > 0 && recordsRead>=nRecords){
				    return false;
				}
				//	check that internal buffer has enough data to read data size
				if (LEN_SIZE_SPECIFIER > dataBuffer.remaining()) {
				    reloadBuffer();
                    if(dataBuffer.remaining() == 0) return false;
				}
                recordSize = ByteBufferUtils.decodeLength(dataBuffer);
				
				//	check that internal buffer has enough data to read data record
				if (recordSize > dataBuffer.remaining()){
				    reloadBuffer();
                    if(recordSize > dataBuffer.remaining()) return false;
				}
                dataBuffer.mark();//could be used later for reget
				data.deserialize(dataBuffer);
				
				recordsRead++;
				return true;
			}
		

        boolean reget(DataRecord data) {
            dataBuffer.reset();
            data.deserialize(dataBuffer);
            return true;
        }
        
        
		/**
		 *  Flushes in memory buffer into TMP file
		 *
		 *@exception  IOException  Description of Exception
		 * @throws InterruptedException 
		 *@since                   September 17, 2002
		 */
		private void flushBuffer() throws IOException, InterruptedException {
			try {
				dataBuffer.flip();
				tmpFileChannel.write(dataBuffer);
				dataBuffer.clear();
			} catch (ClosedChannelException e) {
				throw new InterruptedException();
			}
		}
		
		private void reloadBuffer() throws IOException, InterruptedException {
			try {
				dataBuffer.compact();
				tmpFileChannel.read(dataBuffer);
				dataBuffer.flip();
			} catch (ClosedChannelException e) {
				throw new InterruptedException();
			}
		}


		public boolean isEmpty(){
			return (length==0);
		}
	    
		public String toString(){
		    return "start: "+offsetStart+" #records: "+nRecords+" length: "+length;
		}
	}

    /**
     * Returns previously set temporary directory where this DataRecordTape
     * should create its file (temporary)
     * 
     * @return
     */
    public File getTmpDirectory() {
        return tmpDirectory;
    }

    /**
     * Allows to set the temporary directory in which this DataRecordTape will
     * create temporary file to store data.
     * 
     * @param tmpDirectory
     */
    public void setTmpDirectory(File tmpDirectory) {
        this.tmpDirectory = tmpDirectory;
    }
	
}

